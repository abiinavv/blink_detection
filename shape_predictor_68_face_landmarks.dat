import cv2 
import dlib
import imutils
import requests


a1 = "https://blynk.cloud/external/api/update?token=4NO5SmRam0TakCbCQc1Tlt1XQy9mxYWE&V1="

b1 = "https://blynk.cloud/external/api/update?token=4NO5SmRam0TakCbCQc1Tlt1XQy9mxYWE&V2="

a = '1'
b = '1'


 


from scipy.spatial import distance as dist 
from imutils import face_utils



import os
from twilio.rest import Client



account_sid = "AC567aacc13ea344c8f5754ef57a660d48"
auth_token = "c50794dd4c4c7a5fa27009e2514483ac"
client = Client(account_sid, auth_token)






# from imutils import 
k = 0
lb = 0
rb = 0
j = 0
s = 0
f = 0


cam = cv2.VideoCapture(0) 

# defining a function to calculate the EAR 
def calculate_EAR(eye): 

        # calculate the vertical distances 
        y1 = dist.euclidean(eye[1], eye[5]) 
        y2 = dist.euclidean(eye[2], eye[4]) 

        # calculate the horizontal distance 
        x1 = dist.euclidean(eye[0], eye[3]) 

        # calculate the EAR 
        EAR = (y1+y2) / x1 
        return EAR 

# Variables 
blink_thresh = 0.45
succ_frame = 2
count_frame = 0

# Eye landmarks 
(L_start, L_end) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"] 
(R_start, R_end) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye'] 

# Initializing the Models for Landmark and 
# face Detection 
detector = dlib.get_frontal_face_detector() 
landmark_predict = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat') 
while 1:

        

        # If the video is finished then reset it 
        # to the start 
        if cam.get(cv2.CAP_PROP_POS_FRAMES) == cam.get( 
                        cv2.CAP_PROP_FRAME_COUNT): 
                cam.set(cv2.CAP_PROP_POS_FRAMES, 0) 

        else: 
                _, frame = cam.read() 
                frame = imutils.resize(frame, width=640) 

                # converting frame to gray scale to 
                # pass to detector 
                img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) 

                # detecting the faces 
                faces = detector(img_gray) 
                for face in faces: 

                        # landmark detection 
                        shape = landmark_predict(img_gray, face) 

                        # converting the shape class directly 
                        # to a list of (x,y) coordinates 
                        shape = face_utils.shape_to_np(shape) 

                        # parsing the landmarks list to extract 
                        # lefteye and righteye landmarks--# 
                        lefteye = shape[L_start: L_end] 
                        righteye = shape[R_start:R_end] 

                        # Calculate the EAR 
                        left_EAR = calculate_EAR(lefteye) 
                        right_EAR = calculate_EAR(righteye) 

                        # Avg of left and right eye EAR 
                        avg = (left_EAR+right_EAR)/2
                        if avg < blink_thresh:
                                k += 1


                                   
                                 # incrementing the frame count
                                #cv2.putText(frame, '+'+ str((k - s2) /s1), (30, 30),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)  
                                cv2.putText(frame, str(lb), (100, 70),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)
                                cv2.putText(frame, str(rb), (100, 30),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)
                        

                               # if lb > 30 and rb >30:
                                   #print('slept')
                                   #requests.get(a)
                                   #cv2.putText(frame, "boy slept", (30, 120),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)


                                
                                if rb > 2 and lb > 2:
                                   count_frame += 1
                                   





                                if lb > 15 and rb < 5:

                                       lb = 0
                                        
                                       requests.get(a1+a)
                                       print('L1')

                                       if a == '1':
                                          a = '0'
                                       else:
                                          a = '1'
                                       
                                
                                if rb > 15 and lb < 5:

                                        rb = 0
                                        
                                        requests.get(b1+b)
                                        print("L2")
                                        
                                        if b == '1':
                                          b = '0'
                                        else:
                                          b = '1'


                                if (count_frame-s) == 5 :
                                        f += 1
                                        if f == 3:
                                            call = client.calls.create(
                                                 url="http://demo.twilio.com/docs/voice.xml",
                                                 to="+918891056390",
                                                 from_="+15074422427")

                                            print("call")
                                            f = 0


                                
                                        




                                if right_EAR - left_EAR > .01 :
                                        lb += 1
                                       # cv2.putText(frame, "left:"+str(right_EAR - left_EAR), (30, 120),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)

                                if left_EAR - right_EAR > .01 :
                                        
                                        rb += 1
                                        #cv2.putText(frame, "right:"+str(left_EAR - right_EAR), (30, 120),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)


                                
                                 
                                
                        else: 
                                if count_frame >= succ_frame:

                                        
                                        #print(val.status_code)

                                        
                                        cv2.putText(frame, str(count_frame-s), (30, 30),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)   
                                        cv2.putText(frame, str(count_frame), (30, 70),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)
                                        cv2.putText(frame, str(lb), (100, 70),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)
                                        cv2.putText(frame, str(rb), (100, 30),  cv2.FONT_HERSHEY_DUPLEX, 1, (0, 200, 0), 1)

                                        k = 0
                                        lb = 0
                                        rb = 0
                                        s = count_frame
                                        
                                else: 
                                        count_frame = 0

                                        
                                        

                cv2.imshow("Video", frame)

                if cv2.waitKey(5) & 0xFF == ord('q'): 
                        break

cam.release() 
cv2.destroyAllWindows()
